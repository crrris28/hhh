---
title: "QRNN"
output: pdf_document
date: "2024-01-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library("qrnn")
library("GAS")
```

### Simulation 1
#### QRNN
```{r}
simulated_data = read.csv("simulation1.csv")
thetas <- c(0.01,0.05,0.1)
test_loc <- 1001
qrnn_eval <- function(data,thetas,test_loc){
  n <- nrow(data)
  w <- VaR <- qrnn_results <- vector("list", length(thetas))
  test_size <- n-test_loc+1
  for(i in seq_along(thetas)){
    for(j in 1:test_size){
      start_train_x <- j
      end_train_x <- test_loc-3+j
      start_train_y <- j+1
      end_train_y <- test_loc-2+j
      w[[i]] <- qrnn.fit(x=as.matrix(abs(data$y[start_train_x:end_train_x])), y=as.matrix(data$y[start_train_y:end_train_y]), n.hidden=3, tau=thetas[i],
      iter.max=200, n.trials=1)
      VaR[[i]] <- append(VaR[[i]],qrnn.predict(as.matrix(abs(data$y[test_loc-2+j])), w[[i]]))
    }
    p <- sum(simulated_data$y[test_loc:n]<VaR[[i]])/test_size
    length(VaR[[i]])
    ls <- BacktestVaR(simulated_data$y[test_loc:n], VaR[[i]], theta)
    uc_p <- ls$LRuc['Pvalue']
    cc_p <- ls$LRcc['Pvalue']
    qrnn_results[[i]] <- c(p,uc_p,cc_p)
    }
  return(qrnn_results)
}
qrnn_results <- qrnn_eval(simulated_data,thetas,test_loc)
```


```{r}
#测试测试
data <- simulated_data
qarnn.fit(x=as.matrix(abs(data$y[1:999])), y=as.matrix(data$y[2:1000]), n.hidden=3, tau=0.05, iter.max=5000)

library("optimg")
optimg
```


#### QARNN
```{r}
#tau is theta, the quantile level
#改了下iter.max(5000), tau=0.5
qarnn.fit <- function (x, y, n.hidden, w = 1, tau = 0.05, n.ensemble = 1, 
  iter.max = 10000, n.trials = 5, bag = FALSE, lower = -Inf, 
  init.range = c(-0.5, 0.5, -0.5, 0.5), monotone = NULL, additive = FALSE, 
  eps.seq = 2^seq(-8, -32, by = -4), Th = sigmoid, Th.prime = sigmoid.prime, 
  penalty = 0, unpenalized = NULL, n.errors.max = 10, trace = TRUE,p=1, 
  ...) 
{
  if (!is.matrix(x)) 
    stop("\"x\" must be a matrix")
  if (!is.matrix(y)) 
    stop("\"y\" must be a matrix")
  if (any(is.na(c(x, y)))) 
    stop("missing values in \"x\" or \"y\"")
  if (any(apply(x, 2, sd) < .Machine$double.eps^0.5)) 
    stop("zero variance column(s) in \"x\"")
  if (ncol(y) != 1) 
    stop("\"y\" must be univariate")
  if (any((tau > 1) | (tau < 0))) 
    stop("invalid \"tau\"")
  if (!identical(Th, linear) && missing(n.hidden)) 
    stop("must specify \"n.hidden\"")
  if (identical(Th, linear)) 
    n.hidden <- 1
  is.whole <- function(x, tol = .Machine$double.eps^0.5) abs(x - 
    round(x)) < tol
  if (additive && !is.whole(n.hidden/ncol(x))) 
    stop("\"n.hidden\" must be an integer multiple of \"ncol(x)\" when \"additive=TRUE\"")
  if (is.null(w)) 
    w <- rep(1/nrow(y), nrow(y))
  if (any(w < 0)) 
    stop("invalid \"w\"")
  x <- scale(x)
  x.center <- attr(x, "scaled:center")
  x.scale <- attr(x, "scaled:scale")
  y <- scale(y)
  y.center <- attr(y, "scaled:center")
  y.scale <- attr(y, "scaled:scale")
  lower.scaled <- (lower - y.center)/y.scale
  if (additive) 
    additive <- gam.mask(x, n.hidden)
  weights <- vector("list", n.ensemble)
  if (trace) 
    cat("tau =", unique(tau), "\n", sep = " ")
  for (i in seq(n.ensemble)) {
    if (trace) 
      cat(i, "/", n.ensemble, "\n", sep = "")
    w.tmp <- NA
    class(w.tmp) <- "try-error"
    n.errors <- 0
    while (inherits(w.tmp, "try-error")) {
      w.tmp <- try(qarnn.nlm(x, y, n.hidden, w, tau, iter.max, 
        n.trials, bag, lower.scaled, init.range, monotone, 
        additive, eps.seq, Th, Th.prime, penalty, unpenalized, 
        trace,p=1, ...), silent = TRUE)
      n.errors <- n.errors + 1
      #if (n.errors > n.errors.max) 
        #stop("nlm optimization failed")
    }
    weights[[i]] <- w.tmp
  }
  if (trace) 
    cat("\n")
  parms <- list(weights = weights, lower = lower, eps.seq = eps.seq, 
    tau = tau, Th = Th, x.center = x.center, x.scale = x.scale, 
    y.center = y.center, y.scale = y.scale, monotone = monotone, 
    additive = additive)
  parms
}





qarnn.nlm <- function (x, y, n.hidden, w, tau, iter.max, n.trials, bag, lower, 
  init.range, monotone, additive, eps.seq, Th, Th.prime, penalty, 
  unpenalized, trace,p=1,...) 
{
  cases <- seq(nrow(x))
  if (bag) 
    cases <- sample(nrow(x), replace = TRUE)
  x <- x[cases, , drop = FALSE]
  y <- y[cases, , drop = FALSE]
  w <- w[cases]
  if (length(tau) > 1) 
    tau <- tau[cases]
  if (length(lower) > 1) 
    lower <- lower[cases]
  eps.seq <- sort(eps.seq, decreasing = TRUE)
  cost.best <- Inf
  for (i in seq(n.trials)) {
    weights <- qarnn.initialize(x, y, n.hidden, init.range,p)
    if (any(lower != -Inf)) {
      for (eps in eps.seq) {
        # fit <- suppressWarnings(nlm(qarnn.cost, weights,
        #   iterlim = iter.max, x = x, y = y, n.hidden = n.hidden,
        #   w = w, tau = tau, lower = -Inf, monotone = monotone,
        #   additive = additive, eps = eps, Th = Th, Th.prime = Th.prime,
        #   penalty = penalty, unpenalized = unpenalized,p=1,
        #   check.analyticals = FALSE, ...))
        # weights <- fit$estimate
        fit <- suppressWarnings(optim(fn = qarnn.cost, par = weights,method = "CG",
          iterlim = iter.max, x = x, y = y, n.hidden = n.hidden,
          w = w, tau = tau, lower = -Inf, monotone = monotone,
          additive = additive, eps = eps, Th = Th, Th.prime = Th.prime,
          penalty = penalty, unpenalized = unpenalized,p=1,
          check.analyticals = FALSE, ...))
        weights <- fit$par
      }
    }
    for (eps in eps.seq) {
      # fit <- suppressWarnings(nlm(qarnn.cost, weights, 
      #   iterlim = iter.max, x = x, y = y, n.hidden = n.hidden, 
      #   w = w, tau = tau, lower = lower, monotone = monotone, 
      #   additive = additive, eps = eps, Th = Th, Th.prime = Th.prime, 
      #   penalty = penalty, unpenalized = unpenalized, p=1,
      #   check.analyticals = FALSE, ...))
      # weights <- fit$estimate
        fit <- suppressWarnings(optim(fn = qarnn.cost, par = weights,method = "CG",
          iterlim = iter.max, x = x, y = y, n.hidden = n.hidden,
          w = w, tau = tau, lower = -Inf, monotone = monotone,
          additive = additive, eps = eps, Th = Th, Th.prime = Th.prime,
          penalty = penalty, unpenalized = unpenalized,p=1,
          check.analyticals = FALSE, ...))
        weights <- fit$par
    }
    cost <- fit$minimum
    if (trace) 
      cat(i, cost, "\n")
    if (cost < cost.best) {
      cost.best <- cost
      weights.best <- fit$estimate
    }
  }
  if (trace) 
    cat("*", cost.best, "\n")
  weights.best <- qarnn.reshape(x, y, weights.best, n.hidden,p)
  if (!is.logical(additive)) {
    weights.best$W1 <- weights.best$W1 * additive
  }
  weights.best
}


qarnn.reshape <- function (x, y, weights, n.hidden,p) 
{
  N11 <- ncol(x) + 1 +p
  N12 <- n.hidden
  N1 <- N11 * N12
  W1 <- weights[1:N1]
  W1 <- matrix(W1, N11, N12)
  N21 <- n.hidden + 1
  N22 <- ncol(y)
  N2 <- N1 + N21 * N22
  W2 <- weights[(N1 + 1):N2]
  W2 <- matrix(W2, N21, N22)
  list(W1 = W1, W2 = W2)
}



#add p and VaR0
qarnn.cost <- function (weights, x, y, n.hidden, w, tau, lower=-Inf, monotone, 
  additive, eps, Th, Th.prime, penalty, unpenalized,p=1) 
{
  penalty2 <- ifelse(identical(Th, linear), penalty, 0)
  w1w2 <- qarnn.reshape(x, y, weights, n.hidden,p)
  W1 <- w1w2$W1
  rW1 <- nrow(W1)
  cW1 <- ncol(W1)
  W2 <- w1w2$W2
  rW2 <- nrow(W2)
  cW2 <- ncol(W2)
  if (!is.null(monotone)) {
    W1[monotone, ] <- exp(W1[monotone, ])
    W2[1:(rW2 - 1), ] <- exp(W2[1:(rW2 - 1), ])
  }
  if (!is.logical(additive)) {
    W1 <- W1 * additive
  }
  x <- cbind(x, 1)
  x.mat <- matrix(0,nrow=nrow(x),ncol=ncol(x)+p)
  #modification
  VaR0 <- quantile(y, tau)
  VaR <- c()
  VaR[1] <- VaR0
  aug.y1.mat <- matrix(0,nrow=nrow(x),ncol=n.hidden+1)
  h1.mat <- matrix(0,nrow=nrow(x),ncol=n.hidden)
  
  for(i in 2:nrow(x)){
    xx <- t(as.matrix(c(x[i-1,],VaR[i-1])))
    x.mat[i-1,] <- xx
    h1 <- xx %*% W1
    h1.mat[i-1,] <- h1
    y1 <- Th(h1)
    aug.y1 <- cbind(y1, 1)
    aug.y1.mat[i-1,] <- aug.y1
    h2 <- aug.y1 %*% W2
    y2 <- hramp(h2, lower, eps)
    VaR[i] <- y2
  }

  
  E <- y - VaR
  delta2 <- hramp.prime(h2, lower, eps) * tilted.approx.prime(E, 
    tau, eps)
  gradient.W2 <- -(t(aug.y1.mat) %*% sweep(delta2, 1, w, "*"))
  
  if (!is.null(monotone)) {
    gradient.W2[1:(rW2 - 1), ] <- gradient.W2[1:(rW2 - 1), 
      ] * W2[1:(rW2 - 1), ]
  }
  gradient.W2.penalty <- 2 * penalty2 * rbind(W2[1:(rW2 - 
    1), , drop = FALSE], 0)/(length(W2) - cW2)
  E1 <- delta2 %*% t(W2[1:(rW2 - 1), , drop = FALSE])
  delta1 <- Th.prime(h1.mat) * E1
  gradient.W1 = -(t(x.mat) %*% sweep(delta1, 1, w, "*")) 
  
  if (!is.null(monotone)) {
    gradient.W1[monotone, ] <- gradient.W1[monotone, ] * 
      W1[monotone, ]
  }
  W1p <- W1
  W1p[c(unpenalized, rW1), ] <- 0
  gradient.W1.penalty <- 2 * penalty * W1p/sum(W1p != 0)
  cost <- sum(w * tilted.approx(E, tau, eps)) + penalty * 
    sum(W1p^2)/sum(W1p != 0) + penalty2 * sum(W2[1:(rW2 - 
    1), , drop = FALSE]^2)/(length(W2) - cW2)
  gradient <- c(gradient.W1 + gradient.W1.penalty, gradient.W2 + 
    gradient.W2.penalty)
  attr(cost, "gradient") <- gradient
  cost
}



#add a parameter p to indicate how many lags of VaRs are included as predictors
qarnn.initialize <- function (x, y, n.hidden, init.range = c(-0.5, 0.5, -0.5, 0.5), p=1) 
{
  if (!is.list(init.range)) {
    if (length(init.range) == 4) {
      r11 <- init.range[1]
      r12 <- init.range[2]
      r21 <- init.range[3]
      r22 <- init.range[4]
    }
    else {
      r11 <- r21 <- init.range[1]
      r12 <- r22 <- init.range[2]
    }
    W1 <- matrix(runif((ncol(x) + 1 + p) * n.hidden, r11, r12), 
      ncol(x) + 1 + p, n.hidden)
    W2 <- matrix(runif((n.hidden + 1 + p) * ncol(y), r21, r22), 
      n.hidden + 1, ncol(y))
    weights <- c(W1, W2)
  }
  else {
    weights <- unlist(init.range)
  }
  weights
}

```

```{r}
data <- simulated_data
#测试
x=as.matrix(abs(data$y[1:999]))
y=as.matrix(data$y[2:1000])

ww <- qarnn.initialize(x,y,n.hidden  = 3)
w = 1
tau = 0.5
lower = -Inf
monotone = NULL
additive = FALSE
eps = 2^(-8)
Th = sigmoid
Th.prime = sigmoid.prime
penalty = 0
unpenalized = NULL
n.hidden = 3
iter.max=500



##############
#add p and VaR0
qarnn.cost <- function (weights) 
{
  x=as.matrix(abs(data$y[1:999]))
  y=as.matrix(data$y[2:1000])
  n.hidden = 3
  w = 1
  tau = 0.5
  lower = -Inf
  monotone = NULL
  additive = FALSE
  eps = 2^(-8)
  Th = sigmoid
  Th.prime = sigmoid.prime
  penalty = 0
  unpenalized = NULL
  n.hidden = 3
  iter.max=500
  p=1
  
  penalty2 <- ifelse(identical(Th, linear), penalty, 0)
  w1w2 <- qarnn.reshape(x, y, weights, n.hidden,p)
  W1 <- w1w2$W1
  rW1 <- nrow(W1)
  cW1 <- ncol(W1)
  W2 <- w1w2$W2
  rW2 <- nrow(W2)
  cW2 <- ncol(W2)
  if (!is.null(monotone)) {
    W1[monotone, ] <- exp(W1[monotone, ])
    W2[1:(rW2 - 1), ] <- exp(W2[1:(rW2 - 1), ])
  }
  if (!is.logical(additive)) {
    W1 <- W1 * additive
  }
  x <- cbind(x, 1)
  x.mat <- matrix(0,nrow=nrow(x),ncol=ncol(x)+p)
  #modification
  VaR0 <- quantile(y, tau)
  VaR <- c()
  VaR[1] <- VaR0
  aug.y1.mat <- matrix(0,nrow=nrow(x),ncol=n.hidden+1)
  h1.mat <- matrix(0,nrow=nrow(x),ncol=n.hidden)
  
  for(i in 2:nrow(x)){
    xx <- t(as.matrix(c(x[i-1,],VaR[i-1])))
    x.mat[i-1,] <- xx
    h1 <- xx %*% W1
    h1.mat[i-1,] <- h1
    y1 <- Th(h1)
    aug.y1 <- cbind(y1, 1)
    aug.y1.mat[i-1,] <- aug.y1
    h2 <- aug.y1 %*% W2
    y2 <- hramp(h2, lower, eps)
    VaR[i] <- y2
  }

  
  E <- y - VaR
  delta2 <- hramp.prime(h2, lower, eps) * tilted.approx.prime(E, 
    tau, eps)
  gradient.W2 <- -(t(aug.y1.mat) %*% sweep(delta2, 1, w, "*"))
  
  if (!is.null(monotone)) {
    gradient.W2[1:(rW2 - 1), ] <- gradient.W2[1:(rW2 - 1), 
      ] * W2[1:(rW2 - 1), ]
  }
  gradient.W2.penalty <- 2 * penalty2 * rbind(W2[1:(rW2 - 
    1), , drop = FALSE], 0)/(length(W2) - cW2)
  E1 <- delta2 %*% t(W2[1:(rW2 - 1), , drop = FALSE])
  delta1 <- Th.prime(h1.mat) * E1
  gradient.W1 = -(t(x.mat) %*% sweep(delta1, 1, w, "*")) 
  
  if (!is.null(monotone)) {
    gradient.W1[monotone, ] <- gradient.W1[monotone, ] * 
      W1[monotone, ]
  }
  W1p <- W1
  W1p[c(unpenalized, rW1), ] <- 0
  gradient.W1.penalty <- 2 * penalty * W1p/sum(W1p != 0)
  cost <- sum(w * tilted.approx(E, tau, eps)) + penalty * 
    sum(W1p^2)/sum(W1p != 0) + penalty2 * sum(W2[1:(rW2 - 
    1), , drop = FALSE]^2)/(length(W2) - cW2)
  gradient <- c(gradient.W1 + gradient.W1.penalty, gradient.W2 + 
    gradient.W2.penalty)
  attr(cost, "gradient") <- gradient
  cost
}
##############



qarnn.cost(weights) 
  
  
optim(fn = qarnn.cost, par = ww, method = "CG",control=list(trace=TRUE))
  




























w1w2 <- qarnn.reshape(x, y, ww, n.hidden=3,p=1)
W1 <- w1w2$W1
rW1 <- nrow(W1)
cW1 <- ncol(W1)
W2 <- w1w2$W2
rW2 <- nrow(W2)
cW2 <- ncol(W2)
```
```{r}
x=as.matrix(abs(data$y[1:999]))
y=as.matrix(data$y[2:1000])
n.hidden = 3
w = 1
tau = 0.5
lower = -Inf
monotone = NULL
additive = FALSE
eps = 2^(-8)
Th = sigmoid
Th.prime = sigmoid.prime
penalty = 0
unpenalized = NULL
n.hidden = 3
iter.max=500
p=1


best.w <- c(-0.02257107,0.47169769,-0.50395921,-0.15979879,0.36891170,-0.11308306,-0.25763860,0.41419640,-0.20768797,0.49521090,-0.29878851,0.38376040,-0.13206477)

penalty2 <- ifelse(identical(Th, linear), penalty, 0)
w1w2 <- qarnn.reshape(x, y, best.w, n.hidden,p)
W1 <- w1w2$W1
rW1 <- nrow(W1)
cW1 <- ncol(W1)
W2 <- w1w2$W2
rW2 <- nrow(W2)
cW2 <- ncol(W2)
if (!is.null(monotone)) {
  W1[monotone, ] <- exp(W1[monotone, ])
  W2[1:(rW2 - 1), ] <- exp(W2[1:(rW2 - 1), ])
}
if (!is.logical(additive)) {
  W1 <- W1 * additive
}
x <- cbind(x, 1)
x.mat <- matrix(0,nrow=nrow(x),ncol=ncol(x)+p)
#modification
VaR0 <- quantile(y, tau)
VaR <- c()
VaR[1] <- VaR0
aug.y1.mat <- matrix(0,nrow=nrow(x),ncol=n.hidden+1)
h1.mat <- matrix(0,nrow=nrow(x),ncol=n.hidden)

for(i in 2:nrow(x)){
  xx <- t(as.matrix(c(x[i-1,],VaR[i-1])))
  x.mat[i-1,] <- xx
  h1 <- xx %*% W1
  h1.mat[i-1,] <- h1
  y1 <- Th(h1)
  aug.y1 <- cbind(y1, 1)
  aug.y1.mat[i-1,] <- aug.y1
  h2 <- aug.y1 %*% W2
  y2 <- hramp(h2, lower, eps)
  VaR[i] <- y2
}

df <- data.frame(VaR)
df$y <- y

library(ggplot2)
ggplot(data = df)+geom_line(aes(x=1:999,y=VaR,col='red'))+geom_line(aes(x=1:999,y=y))
```
#### Try Alternating Optimization
```{r}

```














```{r}
x <- cbind(x, 1)
#modification
VaR0 <- quantile(y, tau)
VaR <- c()
VaR[1] <- VaR0

for(i in 2:nrow(x)){
  xx <- c(x[i-1,],VaR[i-1])
  h1 <- xx %*% W1
  y1 <- Th(h1)
  aug.y1 <- cbind(y1, 1)
  h2 <- aug.y1 %*% W2
  y2 <- hramp(h2, lower, eps)
  VaR[i] <- y2
}
```



```{r}
w = 1
tau = 0.5
lower = -Inf
monotone = NULL
additive = FALSE
eps = 2^(-8)
Th = sigmoid
Th.prime = sigmoid.prime
penalty = 0
unpenalized = NULL

qarnn.cost(ww, x, y, n.hidden, w, tau, lower, monotone, 
  additive, eps, Th, Th.prime, penalty, unpenalized,p=1) 


penalty2 <- ifelse(identical(Th, linear), penalty, 0)
w1w2 <- qarnn.reshape(x, y, ww, n.hidden,p)
W1 <- w1w2$W1
rW1 <- nrow(W1)
cW1 <- ncol(W1)
W2 <- w1w2$W2
rW2 <- nrow(W2)
cW2 <- ncol(W2)
if (!is.null(monotone)) {
  W1[monotone, ] <- exp(W1[monotone, ])
  W2[1:(rW2 - 1), ] <- exp(W2[1:(rW2 - 1), ])
}
if (!is.logical(additive)) {
  W1 <- W1 * additive
}
x <- cbind(x, 1)
x.mat <- matrix(0,nrow=nrow(x),ncol=ncol(x)+p)
#modification
VaR0 <- quantile(y, tau)
VaR <- c()
VaR[1] <- VaR0
aug.y1.mat <- matrix(0,nrow=nrow(x),ncol=n.hidden+1)
h1.mat <- matrix(0,nrow=nrow(x),ncol=n.hidden)

for(i in 2:nrow(x)){
  xx <- t(as.matrix(c(x[i-1,],VaR[i-1])))
  x.mat[i-1,] <- xx
  h1 <- xx %*% W1
  h1.mat[i-1,] <- h1
  y1 <- Th(h1)
  aug.y1 <- cbind(y1, 1)
  aug.y1.mat[i-1,] <- aug.y1
  h2 <- aug.y1 %*% W2
  y2 <- hramp(h2, lower, eps)
  VaR[i] <- y2
}
#
# h1 <- x %*% W1
# y1 <- Th(h1)
# aug.y1 <- cbind(y1, 1)
# h2 <- aug.y1 %*% W2
# y2 <- hramp(h2, lower, eps)
E <- y - VaR
delta2 <- hramp.prime(h2, lower, eps) * tilted.approx.prime(E, 
  tau, eps)
gradient.W2 <- -(t(aug.y1.mat) %*% sweep(delta2, 1, w, "*"))

if (!is.null(monotone)) {
  gradient.W2[1:(rW2 - 1), ] <- gradient.W2[1:(rW2 - 1), 
    ] * W2[1:(rW2 - 1), ]
}
gradient.W2.penalty <- 2 * penalty2 * rbind(W2[1:(rW2 - 
  1), , drop = FALSE], 0)/(length(W2) - cW2)
E1 <- delta2 %*% t(W2[1:(rW2 - 1), , drop = FALSE])
delta1 <- Th.prime(h1.mat) * E1
gradient.W1 = -(t(x.mat) %*% sweep(delta1, 1, w, "*")) 

if (!is.null(monotone)) {
  gradient.W1[monotone, ] <- gradient.W1[monotone, ] * 
    W1[monotone, ]
}
W1p <- W1
W1p[c(unpenalized, rW1), ] <- 0
gradient.W1.penalty <- 2 * penalty * W1p/sum(W1p != 0)
cost <- sum(w * tilted.approx(E, tau, eps)) + penalty * 
  sum(W1p^2)/sum(W1p != 0) + penalty2 * sum(W2[1:(rW2 - 
  1), , drop = FALSE]^2)/(length(W2) - cW2)
gradient <- c(gradient.W1 + gradient.W1.penalty, gradient.W2 + 
  gradient.W2.penalty)
attr(cost, "gradient") <- gradient
cost
```








### Simulation2
#### QRNN
```{r}
qrnn.nlm
```

#### QARNN
```{r}

```


